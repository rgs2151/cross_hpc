{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335f0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, KFold, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, silhouette_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.stats import wilcoxon\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress Wilcoxon warnings for small samples/ties\n",
    "warnings.filterwarnings('ignore', message='Exact p-value calculation does not work')\n",
    "warnings.filterwarnings('ignore', message='Sample size too small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb0fcd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e23b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "plt.rc('legend', frameon=False)\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_style(\"white\", rc=custom_params)\n",
    "sns.set_palette(\"pastel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b268d62",
   "metadata": {},
   "source": [
    "# Single Neuron Trial Summarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf8728",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d0e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(auc):\n",
    "    plt.imshow(auc, aspect='auto', cmap='rocket')\n",
    "    plt.ylabel('Neurons')\n",
    "    plt.xlabel('Trials')\n",
    "    plt.title('AUC of df/f per trial')\n",
    "    plt.colorbar(label='AUC (df/f)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440daa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df_results, metric='test_acc'):\n",
    "    result = df_results.pivot(index='neuron', columns='target', values=metric)\n",
    "    correlation_matrix = result.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                vmin=-1, vmax=1, square=True)\n",
    "    plt.title('Correlation between Target Decoding Accuracies')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487b1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairwise(df_results, metric='test_acc'):\n",
    "    result = df_results.pivot(index='neuron', columns='target', values=metric)\n",
    "    \n",
    "    # Custom function to add diagonal and chance lines\n",
    "    def add_reference_lines(x, y, **kwargs):\n",
    "        ax = plt.gca()\n",
    "        # Diagonal line\n",
    "        ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=1)\n",
    "        # Chance lines\n",
    "        chance = 0.5\n",
    "        ax.axhline(chance, color='k', linestyle='--', alpha=0.3, linewidth=1)\n",
    "        ax.axvline(chance, color='k', linestyle='--', alpha=0.3, linewidth=1)\n",
    "        # Scatter\n",
    "        ax.scatter(x, y, alpha=0.2, s=10, marker='.', color='k')\n",
    "\n",
    "    # Create pairplot with custom styling\n",
    "    g = sns.pairplot(result, \n",
    "                    diag_kind='hist',\n",
    "                    plot_kws={'alpha': 0.2, 's': 50, 'marker': '.', 'color': 'k'},\n",
    "                    diag_kws={'color': 'k', 'alpha': 0.5},\n",
    "                    corner=False,\n",
    "                    height=3)  # Size of each subplot (default is 2.5)\n",
    "\n",
    "    # Add reference lines to each subplot\n",
    "    g.map_offdiag(add_reference_lines)\n",
    "\n",
    "    # Set limits and grid for all subplots\n",
    "    for ax in g.axes.flatten():\n",
    "        if ax is not None:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.grid(alpha=0.3)\n",
    "            # Increase tick label size\n",
    "            ax.tick_params(labelsize=10)\n",
    "\n",
    "    # Increase axis label size\n",
    "    for ax in g.axes[-1,:]:  # Bottom row (x-labels)\n",
    "        ax.xaxis.label.set_size(12)\n",
    "    for ax in g.axes[:,0]:   # Left column (y-labels)\n",
    "        ax.yaxis.label.set_size(12)\n",
    "\n",
    "    plt.suptitle(f\"Pairwise Decoding {metric.replace('_', ' ').title()}\", y=1.02, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    # set dpi 300\n",
    "    plt.gcf().set_dpi(300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eea5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_balance(trials_table):\n",
    "    \"\"\"\n",
    "    Plot class balance for all 5 target variables as horizontal bar showing proportions.\n",
    "    \"\"\"\n",
    "    ab_mask = (trials_table.context.values == 'ctxA') | (trials_table.context.values == 'ctxB')\n",
    "    cd_mask = (trials_table.context.values == 'ctxC') | (trials_table.context.values == 'ctxD')\n",
    "    \n",
    "    # Define targets with their masks and class labels\n",
    "    targets = [\n",
    "        ('context_ab', trials_table.context.values, ab_mask, 'ctxA', 'ctxB'),\n",
    "        ('context_cd', trials_table.context.values, cd_mask, 'ctxC', 'ctxD'),\n",
    "        ('reward_trial', trials_table.reward_trial.values, np.ones(len(trials_table), dtype=bool), 'No Reward', 'Reward'),\n",
    "        ('water', trials_table.water.values, np.ones(len(trials_table), dtype=bool), 'No Water', 'Water'),\n",
    "        ('lick_or_not', trials_table.lick_or_not.values, np.ones(len(trials_table), dtype=bool), 'No Lick', 'Lick'),\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 1, figsize=(8, 6), sharex=True)\n",
    "    \n",
    "    for ax, (name, data, mask, label_0, label_1) in zip(axes, targets):\n",
    "        masked_data = data[mask]\n",
    "        unique_vals = np.unique(masked_data)\n",
    "        \n",
    "        # Calculate proportion of class 1 (second unique value)\n",
    "        if len(unique_vals) == 2:\n",
    "            prop_1 = np.mean(masked_data == unique_vals[1])\n",
    "            prop_0 = 1 - prop_1\n",
    "        else:\n",
    "            prop_0, prop_1 = 0.5, 0.5\n",
    "        \n",
    "        # Plot horizontal stacked bar\n",
    "        ax.barh(0, prop_0, color='steelblue', alpha=0.7, label=label_0)\n",
    "        ax.barh(0, prop_1, left=prop_0, color='coral', alpha=0.7, label=label_1)\n",
    "        \n",
    "        # Add count annotations\n",
    "        n_0 = int(prop_0 * len(masked_data))\n",
    "        n_1 = int(prop_1 * len(masked_data))\n",
    "        ax.text(prop_0/2, 0, f'{label_0}\\n(n={n_0})', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "        ax.text(prop_0 + prop_1/2, 0, f'{label_1}\\n(n={n_1})', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        ax.set_ylabel(name, fontsize=10)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.axvline(0.5, color='k', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    axes[-1].set_xlabel('Proportion', fontsize=11)\n",
    "    axes[0].set_title('Class Balance for Each Target', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d161fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_accuracy_by_neuron(df_results, metric='test_acc'):\n",
    "    \"\"\"\n",
    "    Simple scatter plot of mean accuracy for all neurons, sorted.\n",
    "    \"\"\"\n",
    "    # Pivot to get neurons x targets\n",
    "    df_pivot = df_results.pivot(index='neuron', columns='target', values=metric)\n",
    "    \n",
    "    # Calculate mean across targets for each neuron\n",
    "    mean_acc = df_pivot.mean(axis=1)\n",
    "    n_total = len(mean_acc)\n",
    "    \n",
    "    # Sort neurons by mean accuracy (descending)\n",
    "    sorted_neurons = mean_acc.sort_values(ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    \n",
    "    y_pos = np.arange(n_total)[::-1]  # Best at top\n",
    "    ax.scatter(sorted_neurons.values, y_pos, s=15, c='steelblue', alpha=0.7)\n",
    "    \n",
    "    # Chance line\n",
    "    ax.axvline(0.5, color='red', linestyle='--', alpha=0.5, linewidth=1, label='Chance')\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xlabel(metric.replace('_', ' ').title(), fontsize=11)\n",
    "    ax.set_ylabel('Neuron (ranked)', fontsize=11)\n",
    "    ax.set_title(f'All {n_total} Neurons', fontsize=12)\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return sorted_neurons.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013bb0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selectivity_histogram(df_results, n_bins=10, figsize=(12, 6), p_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Histogram of signed selectivity per target showing neuron selectivity distribution.\n",
    "    Signed selectivity = (AUC - 0.5) * sign(beta), centered at 0.\n",
    "    Only plots neurons with p_auc < p_thresh.\n",
    "    \"\"\"\n",
    "    targets = df_results['target'].unique()\n",
    "    n_targets = len(targets)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_targets, figsize=figsize, sharey=True)\n",
    "    \n",
    "    for ax, target in zip(axes, targets):\n",
    "        target_data = df_results[(df_results['target'] == target) & (df_results['p_auc'] < p_thresh)]\n",
    "        n_sig = len(target_data)\n",
    "        n_total = len(df_results[df_results['target'] == target])\n",
    "        \n",
    "        auc_values = target_data['test_auc'].values\n",
    "        beta_values = target_data['beta_mean'].values\n",
    "        \n",
    "        # Signed selectivity: direction from beta, magnitude from AUC\n",
    "        signed_selectivity = (auc_values - 0.5) * np.sign(beta_values)\n",
    "        \n",
    "        ax.hist(signed_selectivity, bins=n_bins, range=(-0.5, 0.5), \n",
    "                edgecolor='white', alpha=0.8)\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=1)\n",
    "        ax.set_xlabel('Signed Selectivity')\n",
    "        ax.set_title(f'{target}\\n({n_sig}/{n_total} sig)')\n",
    "        ax.set_xlim(-0.55, 0.55)\n",
    "    \n",
    "    axes[0].set_ylabel('Number of neurons')\n",
    "    plt.suptitle(rf'Signed Selectivity = (AUC - 0.5) $\\times$ sign($\\beta$), p<{p_thresh}', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f78565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neuron_beta_clusters(df_results, max_clusters=10, figsize=(12, 5)):\n",
    "    \"\"\"\n",
    "    PCA on neuron beta coefficients with k-means clustering overlay.\n",
    "    Automatically selects optimal number of clusters via silhouette score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pivot to wide format: neurons × targets\n",
    "    beta_matrix = df_results.pivot(index='neuron', columns='target', values='beta_mean')\n",
    "    \n",
    "    # Z-score the betas\n",
    "    scaler = StandardScaler()\n",
    "    beta_scaled = scaler.fit_transform(beta_matrix.values)\n",
    "    \n",
    "    # Find optimal n_clusters via silhouette score\n",
    "    k_range = range(2, min(max_clusters + 1, len(beta_matrix)))\n",
    "    silhouette_scores = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(beta_scaled)\n",
    "        silhouette_scores.append(silhouette_score(beta_scaled, labels))\n",
    "    \n",
    "    n_clusters = list(k_range)[np.argmax(silhouette_scores)]\n",
    "    \n",
    "    # Final clustering with optimal k\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(beta_scaled)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pcs = pca.fit_transform(beta_scaled)\n",
    "    \n",
    "    # Plot - two square subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # Left: PCA scatter\n",
    "    ax = axes[0]\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))\n",
    "    for i in range(n_clusters):\n",
    "        mask = clusters == i\n",
    "        ax.scatter(pcs[mask, 0], pcs[mask, 1], c=[colors[i]], \n",
    "                   alpha=0.7, edgecolors='w', linewidth=0.5, label=f'Cluster {i}')\n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
    "    ax.set_title(f'Neurons in Beta Space (k={n_clusters}, silhouette={max(silhouette_scores):.2f})')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    \n",
    "    # Right: Cluster profiles\n",
    "    ax = axes[1]\n",
    "    cluster_profiles = pd.DataFrame(beta_scaled, columns=beta_matrix.columns)\n",
    "    cluster_profiles['cluster'] = clusters\n",
    "    mean_profiles = cluster_profiles.groupby('cluster').mean()\n",
    "    \n",
    "    mean_profiles.T.plot(kind='bar', ax=ax, width=0.8, edgecolor='white', color=colors[:n_clusters])\n",
    "    ax.set_xlabel('Target')\n",
    "    ax.set_ylabel('Mean Beta (z-scored)')\n",
    "    ax.set_title('Cluster Encoding Profiles')\n",
    "    ax.legend(title='Cluster', fontsize=8)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.axhline(0, color='k', linestyle='--', linewidth=0.5)\n",
    "    ax.set_aspect('auto')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de592f",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff388408",
   "metadata": {},
   "source": [
    "Different targets to decode:\n",
    "\n",
    "$$\\text{CTX}^{AB}_{trial} = \\beta_0 + \\beta_1 \\cdot \\text{AUC}[\\text{df/f}_{trial}]$$\n",
    "$$\\text{CTX}^{CD}_{trial} = \\beta_0 + \\beta_1 \\cdot \\text{AUC}[\\text{df/f}_{trial}]$$\n",
    "$$\\text{RW}_{trial} = \\beta_0 + \\beta_1 \\cdot \\text{AUC}[\\text{df/f}_{trial}]$$\n",
    "$$\\text{WATER}_{trial} = \\beta_0 + \\beta_1 \\cdot \\text{AUC}[\\text{df/f}_{trial}]$$\n",
    "$$\\text{LICK}_{trial} = \\beta_0 + \\beta_1 \\cdot \\text{AUC}[\\text{df/f}_{trial}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df26986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_neuron_decoding(auc, trials_table):\n",
    "    \"\"\"\n",
    "    Perform single neuron decoding using logistic regression with k-fold cross-validation.\n",
    "    Includes significance testing via Wilcoxon signed-rank test.\n",
    "    \"\"\"\n",
    "    \n",
    "    ab_mask = (trials_table.context.values == 'ctxA') | (trials_table.context.values == 'ctxB')\n",
    "    cd_mask = (trials_table.context.values == 'ctxC') | (trials_table.context.values == 'ctxD')\n",
    "\n",
    "    target_names = ['context_ab', 'context_cd', 'reward_trial', 'water', 'lick_or_not']\n",
    "    target_datas = [trials_table.context.values, trials_table.context.values,\n",
    "                    trials_table.reward_trial.values, trials_table.water.values,\n",
    "                    trials_table.lick_or_not.values]\n",
    "    trial_masks = [ab_mask, cd_mask, np.ones(len(trials_table), dtype=bool),\n",
    "                   np.ones(len(trials_table), dtype=bool), np.ones(len(trials_table), dtype=bool)]\n",
    "\n",
    "    # Precompute accuracy chance levels (majority class proportion per target)\n",
    "    chance_acc = {}\n",
    "    for name, data, mask in zip(target_names, target_datas, trial_masks):\n",
    "        y = data[mask]\n",
    "        chance_acc[name] = max(np.mean(y == u) for u in np.unique(y))\n",
    "\n",
    "    results = []\n",
    "    scoring = {'accuracy': 'accuracy', 'roc_auc': 'roc_auc'}\n",
    "    \n",
    "    for neuron_idx in tqdm.tqdm(range(auc.shape[0]), desc='Decoding neurons'):\n",
    "        for target_name, target_data, trial_mask in zip(target_names, target_datas, trial_masks):\n",
    "            \n",
    "            X = auc[neuron_idx, trial_mask].reshape(-1, 1)\n",
    "            y = target_data[trial_mask]\n",
    "            \n",
    "            # StratifiedKFold preserves class proportions in each fold\n",
    "            skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            cv = cross_validate(LogisticRegression(max_iter=1000), X, y,\n",
    "                                cv=skf, scoring=scoring, return_train_score=True, return_estimator=True)\n",
    "            \n",
    "            auc_folds = cv['test_roc_auc']\n",
    "            acc_folds = cv['test_accuracy']\n",
    "            betas = np.array([est.coef_[0, 0] for est in cv['estimator']])\n",
    "            \n",
    "            # Wilcoxon signed-rank test (non-parametric 1-sample test)\n",
    "            # AUC: null = 0.5, ACC: null = majority class proportion\n",
    "            try:\n",
    "                _, p_auc = wilcoxon(auc_folds - 0.5, alternative='greater')\n",
    "            except ValueError:  # all differences are zero\n",
    "                p_auc = 1.0\n",
    "            try:\n",
    "                _, p_acc = wilcoxon(acc_folds - chance_acc[target_name], alternative='greater')\n",
    "            except ValueError:\n",
    "                p_acc = 1.0\n",
    "            \n",
    "            results.append({\n",
    "                'neuron': neuron_idx,\n",
    "                'target': target_name,\n",
    "                'test_acc': acc_folds.mean(),\n",
    "                'test_auc': auc_folds.mean(),\n",
    "                'chance_acc': chance_acc[target_name],\n",
    "                'p_auc': p_auc,\n",
    "                'p_acc': p_acc,\n",
    "                'beta_mean': betas.mean(),\n",
    "                'beta_std': betas.std(),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2ffbf",
   "metadata": {},
   "source": [
    "# Single Neuron Temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9a005",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec5b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temporal_encoding(ds, metric='test_auc', figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot time-resolved encoding: mean ± SEM across neurons for each target.\n",
    "    Uses target-specific permutation-based chance levels if available.\n",
    "    \"\"\"\n",
    "    data = ds[metric]\n",
    "    time = ds.coords['time'].values\n",
    "    targets = ds.coords['target'].values\n",
    "    \n",
    "    # Map metric to corresponding chance variable\n",
    "    chance_key = 'chance_auc' if 'auc' in metric else 'chance_acc'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(targets)))\n",
    "    \n",
    "    for i, target in enumerate(targets):\n",
    "        target_data = data.sel(target=target)\n",
    "        mean_val = target_data.mean(dim='neuron').values\n",
    "        sem_val = target_data.std(dim='neuron').values / np.sqrt(len(ds.coords['neuron']))\n",
    "        \n",
    "        ax.plot(time, mean_val, label=target, color=colors[i], linewidth=2)\n",
    "        ax.fill_between(time, mean_val - sem_val, mean_val + sem_val, color=colors[i], alpha=0.2)\n",
    "        \n",
    "        # Target-specific chance line\n",
    "        if chance_key in ds:\n",
    "            chance = ds[chance_key].sel(target=target).values\n",
    "            ax.axhline(chance, color=colors[i], linestyle=':', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'Temporal Encoding Dynamics ({metric})')\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50964c95",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_neuron_decoding_temporal(dfof, trials_table, bin_size=5, fs=1.0, n_permutations=100):\n",
    "    \"\"\"\n",
    "    Time-resolved single neuron decoding with k-fold CV and permutation-based chance levels.\n",
    "    \"\"\"\n",
    "    n_neurons, n_trials, n_timepoints = dfof.shape\n",
    "    n_bins = n_timepoints // bin_size\n",
    "    \n",
    "    # Bin via trapz\n",
    "    dfof_truncated = dfof[:, :, :n_bins * bin_size]\n",
    "    dfof_reshaped = dfof_truncated.reshape(n_neurons, n_trials, n_bins, bin_size)\n",
    "    dfof_binned = np.trapz(dfof_reshaped, axis=-1)\n",
    "    \n",
    "    # Time vector\n",
    "    bin_centers = (np.arange(n_bins) + 0.5) * bin_size / fs\n",
    "    \n",
    "    # Target setup\n",
    "    ab_mask = (trials_table.context.values == 'ctxA') | (trials_table.context.values == 'ctxB')\n",
    "    cd_mask = (trials_table.context.values == 'ctxC') | (trials_table.context.values == 'ctxD')\n",
    "    \n",
    "    target_names = ['context_ab', 'context_cd', 'reward_trial', 'water', 'lick_or_not']\n",
    "    target_datas = [trials_table.context.values, trials_table.context.values,\n",
    "                    trials_table.reward_trial.values, trials_table.water.values,\n",
    "                    trials_table.lick_or_not.values]\n",
    "    trial_masks = [ab_mask, cd_mask] + [np.ones(n_trials, dtype=bool)] * 3\n",
    "    \n",
    "    n_targets = len(target_names)\n",
    "    auc_arr = np.full((n_neurons, n_targets, n_bins), np.nan)\n",
    "    acc_arr = np.full((n_neurons, n_targets, n_bins), np.nan)\n",
    "    beta_arr = np.full((n_neurons, n_targets, n_bins), np.nan)\n",
    "    chance_auc = np.full(n_targets, np.nan)\n",
    "    chance_acc = np.full(n_targets, np.nan)\n",
    "    \n",
    "    rng = np.random.default_rng(42)\n",
    "    scoring = {'accuracy': 'accuracy', 'roc_auc': 'roc_auc'}\n",
    "    \n",
    "    # Compute chance levels via permutation\n",
    "    for target_idx, (target_data, trial_mask) in enumerate(zip(target_datas, trial_masks)):\n",
    "        X = dfof_binned[0, trial_mask, 0].reshape(-1, 1)\n",
    "        y = target_data[trial_mask]\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        perm_scores = [cross_validate(LogisticRegression(max_iter=1000), X, rng.permutation(y),\n",
    "                                      cv=skf, scoring=scoring) for _ in range(n_permutations)]\n",
    "        chance_auc[target_idx] = np.mean([s['test_roc_auc'].mean() for s in perm_scores])\n",
    "        chance_acc[target_idx] = np.mean([s['test_accuracy'].mean() for s in perm_scores])\n",
    "    \n",
    "    # Main decoding loop\n",
    "    for neuron_idx in tqdm.tqdm(range(n_neurons), desc='Temporal decoding'):\n",
    "        for t_idx in range(n_bins):\n",
    "            for target_idx, (target_data, trial_mask) in enumerate(zip(target_datas, trial_masks)):\n",
    "                X = dfof_binned[neuron_idx, trial_mask, t_idx].reshape(-1, 1)\n",
    "                y = target_data[trial_mask]\n",
    "                \n",
    "                skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "                cv = cross_validate(LogisticRegression(max_iter=1000), X, y,\n",
    "                                    cv=skf, scoring=scoring, return_estimator=True)\n",
    "                auc_arr[neuron_idx, target_idx, t_idx] = cv['test_roc_auc'].mean()\n",
    "                acc_arr[neuron_idx, target_idx, t_idx] = cv['test_accuracy'].mean()\n",
    "                beta_arr[neuron_idx, target_idx, t_idx] = np.mean([e.coef_[0, 0] for e in cv['estimator']])\n",
    "    \n",
    "    return xr.Dataset(\n",
    "        {'test_auc': (['neuron', 'target', 'time'], auc_arr),\n",
    "         'test_acc': (['neuron', 'target', 'time'], acc_arr),\n",
    "         'beta': (['neuron', 'target', 'time'], beta_arr),\n",
    "         'chance_auc': (['target'], chance_auc),\n",
    "         'chance_acc': (['target'], chance_acc)},\n",
    "        coords={'neuron': np.arange(n_neurons), 'target': target_names, 'time': bin_centers}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b8783",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7214561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse: ek045, Trial ID: 34941, Area: CA1\n",
      "ICRWL.h5 is successfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding neurons:   0%|          | 0/702 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place_maps.pkl is successfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding neurons:  51%|█████     | 357/702 [02:18<02:11,  2.63it/s]"
     ]
    }
   ],
   "source": [
    "for index, row in df_experiments.iterrows():\n",
    "    print(f\"Mouse: {row['mouse_id']}, Trial ID: {row['trial_id']}, Area: {row['area']}\")\n",
    "    \n",
    "    # Lets read\n",
    "    mouse = Mouse.from_database(\n",
    "        trial_id=row['trial_id'],\n",
    "        mouse_name=row['mouse_id'],\n",
    "        expt_class=ImagingExperiment\n",
    "    ) # returns df\n",
    "    expt = mouse[0] # df\n",
    "    bd_exp = expt.format_behavior_data() # dict\n",
    "    # for key in bd_exp.keys(): print(key)\n",
    "    \n",
    "    # Get or Make ICRWL and place maps\n",
    "    ICRWL = get_or_make_ICRWL(expt, bd_exp)\n",
    "    place_maps, smooth_place_maps = get_or_make_place_maps(expt)\n",
    "    \n",
    "    trials_table = ICRWL.reset_index()[['lap_index', 'context', 'reward_trial', 'water', 'lick_or_not']]\n",
    "    \n",
    "    # Cropping cuz smooth place maps records more trails than behavioral data\n",
    "    dfof = smooth_place_maps[:,:len(trials_table), :]\n",
    "    auc = np.trapz(dfof, axis=2)\n",
    "    \n",
    "    # Core analysis\n",
    "    df_results = single_neuron_decoding(auc, trials_table)\n",
    "\n",
    "    plot_auc(auc) # Basically the raw feature matrix\n",
    "    plot_class_balance(trials_table)\n",
    "    plot_test_accuracy_by_neuron(df_results, metric='test_acc') # Accuracy summary for all neurons\n",
    "    plot_pairwise(df_results, metric='test_acc') # Target x Target pairwise plots\n",
    "    plot_correlation_heatmap(df_results) # Correlation in accuracy between targets\n",
    "    plot_selectivity_histogram(df_results, n_bins=5, figsize=(12, 4)) # Histogram of ROC per target\n",
    "    plot_neuron_beta_clusters(df_results, max_clusters=10, figsize=(12,5))\n",
    "    \n",
    "    \n",
    "    # Core analysis\n",
    "    xr_results = single_neuron_decoding_temporal(dfof, trials_table, bin_size=5, fs=1.0)\n",
    "    \n",
    "    plot_temporal_encoding(xr_results, metric='test_auc', figsize=(10,6))\n",
    "    plot_temporal_encoding(xr_results, metric='test_acc', figsize=(10,6))\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
